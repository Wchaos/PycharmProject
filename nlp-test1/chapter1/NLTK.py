import nltk
nltk.download()
# from nltk import bigrams
# from nltk.book import *

# import matplotlib as plt
# from nltk import FreqDist

# fdist1 = FreqDist(text1)
# print(fdist1)
# vocabulary = fdist1.most_common(50)
# print(vocabulary)
# high_freq_word = [word for (word, freq) in fdist1.most_common(50)]
# print(high_freq_word)
# print(vocabulary)
# print(fdist1['whale'])

# fdist1.plot(50, cumulative=True)
# print(fdist1.hapaxes())
# V = set(text1)
# long_word = [ w for w in V if len(w) > 15 ]
# print(sorted(long_word))

# fdist5 = FreqDist(text5)
# long_freq_word =  [ w for w in set(text5) if len(w) > 7 and fdist5[w] > 7]
# print(sorted(long_freq_word))
# aaa = bigrams(['more', 'is', 'said', 'than', 'done'])
# print([(a, b) for (a, b) in aaa ]
# text4.collocations()

# print([len(w) for w in text1])
# fdist = FreqDist([len(w) for w in text1])
# fdist.tabulate()
# fdist.plot()
# fdist.plot(cumulative=True)



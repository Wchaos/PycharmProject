{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6-1 有监督分类\n",
    "性别分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "    [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义特征提取器\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1],\n",
    "           'word_len' : len(word),\n",
    "           'first_letter' : word[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]#提取特征\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]#设置训练和测试集\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)#训练分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n             last_letter = 'a'            female : male   =     35.5 : 1.0\n             last_letter = 'k'              male : female =     31.1 : 1.0\n             last_letter = 'f'              male : female =     14.7 : 1.0\n             last_letter = 'p'              male : female =     12.7 : 1.0\n             last_letter = 'v'              male : female =     11.3 : 1.0\n             last_letter = 'd'              male : female =     10.3 : 1.0\n             last_letter = 'm'              male : female =      9.9 : 1.0\n             last_letter = 'o'              male : female =      8.2 : 1.0\n             last_letter = 'r'              male : female =      6.6 : 1.0\n             last_letter = 'w'              male : female =      6.3 : 1.0\n             last_letter = 'g'              male : female =      5.1 : 1.0\n            first_letter = 'W'              male : female =      5.0 : 1.0\n             last_letter = 'z'              male : female =      4.4 : 1.0\n             last_letter = 't'              male : female =      4.2 : 1.0\n             last_letter = 's'              male : female =      4.2 : 1.0\n             last_letter = 'j'              male : female =      4.0 : 1.0\n             last_letter = 'i'            female : male   =      3.9 : 1.0\n             last_letter = 'u'              male : female =      3.9 : 1.0\n             last_letter = 'b'              male : female =      3.5 : 1.0\n            first_letter = 'X'              male : female =      2.9 : 1.0\n            first_letter = 'U'              male : female =      2.9 : 1.0\n                word_len = 2                male : female =      2.6 : 1.0\n            first_letter = 'Q'              male : female =      2.6 : 1.0\n            first_letter = 'K'            female : male   =      2.3 : 1.0\n            first_letter = 'H'              male : female =      2.3 : 1.0\n             last_letter = 'n'              male : female =      2.1 : 1.0\n                word_len = 3                male : female =      1.9 : 1.0\n             last_letter = 'x'              male : female =      1.9 : 1.0\n             last_letter = 'l'              male : female =      1.8 : 1.0\n             last_letter = 'e'            female : male   =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#输出对分类最有效的特征\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n             last_letter = 'a'            female : male   =     35.5 : 1.0\n             last_letter = 'k'              male : female =     31.1 : 1.0\n             last_letter = 'f'              male : female =     14.7 : 1.0\n             last_letter = 'p'              male : female =     12.7 : 1.0\n             last_letter = 'v'              male : female =     11.3 : 1.0\n             last_letter = 'd'              male : female =     10.3 : 1.0\n             last_letter = 'm'              male : female =      9.9 : 1.0\n             last_letter = 'o'              male : female =      8.2 : 1.0\n             last_letter = 'r'              male : female =      6.6 : 1.0\n             last_letter = 'w'              male : female =      6.3 : 1.0\n             last_letter = 'g'              male : female =      5.1 : 1.0\n            first_letter = 'W'              male : female =      5.0 : 1.0\n             last_letter = 'z'              male : female =      4.4 : 1.0\n             last_letter = 't'              male : female =      4.2 : 1.0\n             last_letter = 's'              male : female =      4.2 : 1.0\n             last_letter = 'j'              male : female =      4.0 : 1.0\n             last_letter = 'i'            female : male   =      3.9 : 1.0\n             last_letter = 'u'              male : female =      3.9 : 1.0\n             last_letter = 'b'              male : female =      3.5 : 1.0\n            first_letter = 'X'              male : female =      2.9 : 1.0\n            first_letter = 'U'              male : female =      2.9 : 1.0\n                word_len = 2                male : female =      2.6 : 1.0\n            first_letter = 'Q'              male : female =      2.6 : 1.0\n            first_letter = 'K'            female : male   =      2.3 : 1.0\n            first_letter = 'H'              male : female =      2.3 : 1.0\n             last_letter = 'n'              male : female =      2.1 : 1.0\n                word_len = 3                male : female =      1.9 : 1.0\n             last_letter = 'x'              male : female =      1.9 : 1.0\n             last_letter = 'l'              male : female =      1.8 : 1.0\n             last_letter = 'e'            female : male   =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#输出对分类最有效的特征\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "Most Informative Features\n",
      " contains(unimaginative) = True              neg : pos    =      8.4 : 1.0\n",
      "        contains(sexist) = True              neg : pos    =      7.8 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      7.1 : 1.0\n",
      "       contains(singers) = True              pos : neg    =      6.3 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =      6.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set) )\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_reviews' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2f8bf9bda797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmovie_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(sorted(all_words.items(), key=itemgetter(1),reverse=True))#按频率排序\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdocument_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'movie_reviews' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "from operator import itemgetter\n",
    "# print(sorted(all_words.items(), key=itemgetter(1),reverse=True))#按频率排序\n",
    "word_features = list(all_words.keys())[:2000]\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'he', 'the', 'n', 'on', 'ton', 'y', 'ty', 'nty', 'd', 'nd', 'and', 'ry', 'ury', 'id', 'aid', 'ay', 'day', 'an', 'ion', 'f', 'of', 's', \"'s\", \"a's\", 't', 'nt', 'ent', 'ary', 'ed', 'ced', '`', '``', 'o', 'no', 'ce', 'nce', \"'\", \"''\", 'at', 'hat', 'ny', 'any', 'es', 'ies', 'k', 'ok', 'ook', 'ace', '.', 'r', 'er', 'her', 'in', 'end', 'ts', 'nts', 'ity', 've', 'ive', 'ee', 'tee', ',', 'h', 'ch', 'ich', 'ad', 'had', 'l', 'll', 'all', 'ge', 'rge', 'ves', 'se', 'ise', 'ks', 'nks', 'a', 'ta', 'nta', 'or', 'for', 'ner', 'as', 'was', 'ted', 'ber', 'm', 'rm', 'erm', 'en', 'een', 'ged', 'by', 'ior', 'rt', 'urt', 'dge', 'od']\n"
     ]
    }
   ],
   "source": [
    "#找到常用后缀\n",
    "from nltk.corpus import brown\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]]+=1\n",
    "    suffix_fdist[word[-2:]]+=1\n",
    "    suffix_fdist[word[-3:]]+=1\n",
    "common_suffixes = list(suffix_fdist.keys())[:100]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "以词缀为特征训练决策树，标注词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征提取函数\n",
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith(%s)' % suffix] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'he', 'the', 'n', 'on', 'ton', 'y', 'ty', 'nty', 'd', 'nd', 'and', 'ry', 'ury', 'id', 'aid', 'ay', 'day', 'an', 'ion', 'f', 'of', 's', \"'s\", \"a's\", 't', 'nt', 'ent', 'ary', 'ed', 'ced', '`', '``', 'o', 'no', 'ce', 'nce', \"'\", \"''\", 'at', 'hat', 'ny', 'any', 'es', 'ies', 'k', 'ok', 'ook', 'ace', '.', 'r', 'er', 'her', 'in', 'end', 'ts', 'nts', 'ity', 've', 'ive', 'ee', 'tee', ',', 'h', 'ch', 'ich', 'ad', 'had', 'l', 'll', 'all', 'ge', 'rge', 'ves', 'se', 'ise', 'ks', 'nks', 'a', 'ta', 'nta', 'or', 'for', 'ner', 'as', 'was', 'ted', 'ber', 'm', 'rm', 'erm', 'en', 'een', 'ged', 'by', 'ior', 'rt', 'urt', 'dge', 'od']\n"
     ]
    }
   ],
   "source": [
    "#找到常用后缀\n",
    "from nltk.corpus import brown\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]]+=1\n",
    "    suffix_fdist[word[-2:]]+=1\n",
    "    suffix_fdist[word[-3:]]+=1\n",
    "common_suffixes = list(suffix_fdist.keys())[:100]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征提取函数\n",
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith(%s)' % suffix] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)#训练决策树，需要10分左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5689706613625062"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "探索上下文语境：\n",
    "把前一个单词作为特征，加入特征集，训练贝叶斯分类器"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "序列分类：\n",
    "把对前一个单词的预测作为特征，加入特征集，训练贝叶斯分类器"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6-2 有监督分类的更多例子\n",
    "句子分割"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

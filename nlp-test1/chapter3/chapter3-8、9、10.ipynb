{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3-8 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import gutenberg \n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "断句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the wild events which were to follow this girl had no\\n'\n",
      " 'part at all; he never saw her again until all his tale was over.',\n",
      " 'And yet, in some indescribable way, she kept recurring like a\\n'\n",
      " 'motive in music through all his mad adventures afterwards, and the\\n'\n",
      " 'glory of her strange hair ran like a red thread through those dark\\n'\n",
      " 'and ill-drawn tapestries of the night.',\n",
      " 'For what followed was so\\nimprobable, that it might well have been a dream.',\n",
      " 'When Syme went out into the starlit street, he found it for the\\n'\n",
      " 'moment empty.',\n",
      " 'Then he realised (in some odd way) that the silence\\n'\n",
      " 'was rather a living silence than a dead one.',\n",
      " 'Directly outside the\\n'\n",
      " 'door stood a street lamp, whose gleam gilded the leaves of the tree\\n'\n",
      " 'that bent out over the fence behind him.',\n",
      " 'About a foot from the\\n'\n",
      " 'lamp-post stood a figure almost as rigid and motionless as the\\n'\n",
      " 'lamp-post itself.',\n",
      " 'The tall hat and long frock coat were black; the\\n'\n",
      " 'face, in an abrupt shadow, was almost as dark.',\n",
      " 'Only a fringe of\\n'\n",
      " 'fiery hair against the light, and also something aggressive in the\\n'\n",
      " 'attitude, proclaimed that it was the poet Gregory.',\n",
      " 'He had something\\n'\n",
      " 'of the look of a masked bravo waiting sword in hand for his foe.']\n"
     ]
    }
   ],
   "source": [
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')#载入punkt分割器内部数据\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')#读取生语料\n",
    "sents = sent_tokenizer.tokenize(text)#断句\n",
    "pprint.pprint(sents[171:181])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "分词\n",
    "一些书写系统，由于没有词边界的可视表示这一事实，文本分词变得更加困难。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last:i+1])\n",
    "            last = i+1\n",
    "    words.append(text[last:])\n",
    "    return words\n",
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"#原始文本\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"#分词标记1\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"#分词标记2\n",
    "segment(text, seg1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "计算目标函数,得分值越小表明分词越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "47\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = len(' '.join(list(set(words))))\n",
    "    return text_size + lexicon_size\n",
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "print(evaluate(text, seg3))\n",
    "print(evaluate(text, seg2))\n",
    "print(evaluate(text, seg1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用模拟退火算法的非确定性搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "60 ['doyouseet', 'hekitty', 'see', 'thedoggy', 'doyoulik', 'et', 'hekitty', 'li', 'k', 'e', 'thedoggy']\n",
      "60 ['doyouseet', 'hekitty', 'see', 'thedoggy', 'doyoulik', 'et', 'hekitty', 'li', 'k', 'e', 'thedoggy']\n",
      "60 ['doyouseet', 'hekitty', 'see', 'thedoggy', 'doyoulik', 'et', 'hekitty', 'li', 'k', 'e', 'thedoggy']\n",
      "58 ['doyo', 'useet', 'hekitty', 'see', 'thed', 'oggy', 'doyo', 'u', 'lik', 'e', 't', 'hekitty', 'lik', 'e', 'thed', 'oggy']\n",
      "57 ['doyo', 'useet', 'hekitty', 's', 'eethed', 'oggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hed', 'oggy']\n",
      "57 ['doyo', 'useet', 'hekitty', 's', 'eethed', 'oggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hed', 'oggy']\n",
      "55 ['doyo', 'useet', 'hekitty', 's', 'eet', 'hed', 'oggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hed', 'oggy']\n",
      "48 ['doyo', 'u', 'seet', 'hekitty', 'seet', 'hed', 'oggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hed', 'oggy']\n",
      "45 ['doyo', 'u', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "45 ['doyo', 'u', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyo', 'u', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "42 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000100010000001000100000010000100001000000100001000000'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "def flip(segs, pos):\n",
    "    return segs[:pos] + str(1-int(segs[pos])) + segs[pos+1:]\n",
    "def flip_n(segs, n):\n",
    "    for i in range(n):\n",
    "        segs = flip(segs, randint(0,len(segs)-1))#随机扰动n次\n",
    "    return segs\n",
    "def anneal(text, segs, iterations, cooling_rate):\n",
    "    temperature = float(len(segs))\n",
    "    while temperature > 0.5:\n",
    "        best_segs, best = segs, evaluate(text, segs)\n",
    "        for i in range(iterations):\n",
    "            guess = flip_n(segs, int(round(temperature)))\n",
    "            score = evaluate(text, guess)\n",
    "            if score < best:\n",
    "                best, best_segs = score, guess\n",
    "        score, segs = best, best_segs\n",
    "        temperature = temperature / cooling_rate\n",
    "        print(evaluate(text, segs),end = \" \")\n",
    "        print(segment(text, segs))\n",
    "    return segs\n",
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "anneal(text, seg1, 5000, 1.2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3-9 格式化：从链表到字符串\n",
    "词的链表转换成字符串，使用的join()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We called him Tortoise because he taught us .\n",
      "We;called;him;Tortoise;because;he;taught;us;.\n",
      "WecalledhimTortoisebecausehetaughtus.\n"
     ]
    }
   ],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "#指定不同的连接符\n",
    "print(' '.join(silly))\n",
    "print(';'.join(silly))\n",
    "print(''.join(silly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
